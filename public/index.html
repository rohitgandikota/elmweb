<!doctype html>
<html lang="en">
<head>
<title>Erasing Conceptual Knowledge from Language Models</title>
<meta name="viewport" content="width=device-width,initial-scale=1" />
<meta name="description" content="Addressing bias, copyright, and offensive content in diffusion models by directly calculating parameter changes." />
<meta property="og:title" content="Unified Concept Editing in Diffusion Models" />
<meta property="og:description" content="Addressing bias, copyright, and offensive content in diffusion models by directly calculating parameter changes." />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" /> 
<meta name="twitter:title" content="Unified Concept Editing in Diffusion Models" />
<meta name="twitter:description" content="Addressing bias, copyright, and offensive content in diffusion models by directly calculating parameter changes." />
<link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
<link rel="manifest" href="/site.webmanifest">

<link href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.6/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-rwoIResjU2yc3z8GV/NPeZWAv56rSmLldC3R/AZzGRnGxQQKnKkoFVhFQhNUwEyJ" crossorigin="anonymous">
<script src="https://code.jquery.com/jquery-3.2.1.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Noto+Sans+Math&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,700" rel="stylesheet">
<link href="style.css" rel="stylesheet">

<style>
.relatedthumb {
  float:left; width: 200px; margin: 3px 10px 7px 0;
}
.relatedblock {
  clear: both;
  display: inline-block;
}
.bold-sc {
  font-variant: small-caps;
  font-weight: bold;
}
.cite, .citegroup {
  margin-bottom: 8px;
}
:target {
  background-color: yellow;
}
</style>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-FD12LWN557"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date()); gtag('config', 'G-FD12LWN557');
</script>

</head>
<body class="nd-docs">
<div class="nd-pageheader">
 <div class="container">
 <h1 class="lead">
 Erasing 
 <nobr class="widenobr">Conceptual Knowledge</nobr>
from
 <nobr class="widenobr">Language Models</nobr>
 </h1>
<address>
  <nobr><a href="https://rohitgandikota.github.io/" target="_blank"
  >Rohit Gandikota</a><sup>1</sup>,</nobr>
  <nobr><a href="https://sfeucht.github.io" target="_blank"
  >Sheridan Feucht</a><sup>1</sup>,</nobr>
  <nobr><a href="https://people.math.harvard.edu/~smarks/" target="_blank"
  >Samuel Marks</a><sup>2</sup>,</nobr>
  <nobr><a href="https://baulab.info/" target="_blank"
  >David Bau</a><sup>1</sup></nobr>
 <br>
  <nobr><sup>1</sup><a href="https://khoury.northeastern.edu/" target="_blank"
  >Northeastern University</a>,</nobr>
  <nobr><sup>2</sup><a href="https://www.anthropic.com" target="_blank"
  >Anthropic</a></nobr>;

</address>
 </div>
</div><!-- end nd-pageheader -->

<div class="container">
<div class="row justify-content-center text-center">

<p>
<a href="https://arxiv.org/pdf/2308.14761.pdf" class="d-inline-block p-3 align-top" target="_blank"><img height="100" width="78" src="images/paper-thumb.png" style="border:1px solid; margin: 0 38px;" alt="ArXiv Preprint thumbnail" data-nothumb=""><br>ArXiv<br>Preprint</a>
<a href="https://github.com/rohitgandikota/erasing-llm" class="d-inline-block p-3 align-top" target="_blank"><img height="100" width="78" src="images/code-thumb.png" style="border:1px solid; margin: 0 38px;" alt="Github code thumbnail" data-nothumb=""><br>Source Code<br>Github</a>
<!-- <a href="https://unified.baulab.info/weights/uce_models/" class="d-inline-block p-3 align-top" target="_blank"><img height="100" width="78" src="images/data-thumb.png" style="border:1px solid; margin: 0 38px;" alt="Data thumbnail" data-nothumb=""><br>Fine-Tuned<br>Model  Weights</a> -->
<!-- <a href="https://huggingface.co/spaces/baulab/Erasing-Concepts-In-Diffusion" class="d-inline-block p-3 align-bottom" target="_blank"><img height="78" width="104" src="images/demo3x4-thumb.png" style="border:1px solid" alt="Huggingface demo thumbnail" data-nothumb=""><br>Huggingface<br>Demo</a> -->
</p>

<div class="card" style="max-width: 1020px;">
<div class="card-block">
<h3>What does it mean to erase conceptual knowledge from a language model?</h3>
<p>
    <p>
        Erasing conceptual knowledge from a language model involves the intricate process of removing specific information or capabilities while maintaining the model's overall functionality. This task presents unique challenges that require a comprehensive approach. To achieve effective concept erasure, we propose three key criteria that must be met simultaneously. <b>Innocence: </b>the model should exhibit innocence, completely forgetting the targeted knowledge and showing no signs of retaining the information regardless of how it's prompted or probed. <b>Seamlessness: </b>, the model should generate fluent, coherent text that gracefully handles the absence of the target knowledge rather than generating nonsensical output when prompted about erased concepts. <b>Specificity: </b> the erasure must be specific, ensuring that the process does not impact the model's performance on unrelated tasks or concepts, thus maintaining its general capabilities.
    </p>
    
<p>
In this paper, we present a method that considers all these criteria to effectively erase concepts from language models.
  Our method, <b>Erasure of Language Memory (ELM)</b>, works by employing targeted low-rank updates to alter output distributions for erased concepts. It uses a multi-objective approach that balances erasure, retention of general knowledge, and conditional fluency. This method allows us to remove specific conceptual knowledge while preserving the model's overall capabilities and ensuring seamless text generation even when prompted about erased topics.
</p>
</div><!--card-block-->
</div><!--card-->

</div><!--row-->
  
<div class="row">
<div class="col">
  
<figure class="center_image" style="margin-top: 30px">
  <center><img src="images/paper/method.png" style="width:100%; max-width:800px"></center>
  <figcaption>An overview of our desiderata for concept erasure and Erasure of Language Memory method. The erased model must stay innocent of the erased concept, while still being fluent when prompted for the concept indicating seamless edit. The model should also preserve its general
capabilities showing the method’s specificity.</figcaption>
</figure>

  <h2>Why erase a concept from language model? </h2>
<p>Concept erasure in language models addresses several critical issues. It helps mitigate <a href="https://www.nytimes.com/2023/12/27/business/media/new-york-times-open-ai-microsoft-lawsuit.html">copyright infringement risks</a> by removing potentially reproduced content. It enhances privacy protection by eliminating <a href="https://arxiv.org/abs/2311.17035">sensitive personal information</a> retained from training data. Safety is improved by erasing knowledge of <a href="https://www.wmdp.ai">dangerous concepts</a>. Selective removal of certain concepts aids in reducing <a href="https://dl.acm.org/doi/10.1145/3597307">model biases</a>. Lastly, concept erasure offers a more efficient alternative to full model retraining when updating or correcting specific information, saving significant time and computational resources.</p>

<h2>How to erase concepts from language models?</h2>
  <p>Our Erasure of Language Memory (ELM) method is designed to address all four criteria of effective concept erasure. ELM employs a multi-objective approach that balances erasure, retention of general knowledge, and conditional fluency. The method works by fine-tuning low-rank adapters on Large Language Models (LLMs) using three key loss terms:</p>
    
<ol>
    <li><strong>Erasing Objective (L<sub>erase</sub>):</strong> This term encourages the model to reduce the likelihood of generating content related to the erased concept. It's defined as:
        <img src="images/paper/erase.png" alt="Equation for Erasing Objective" />
        <p>Where P<sub>erased</sub><sub>θ</sub> is a modified probability distribution that reduces the likelihood of the erased concept. This objective ensures that when processing input from the erase dataset, the model's predicted probabilities diverge from the original distribution, effectively reducing the likelihood of tokens associated with the concept being erased.</p>
    </li>

    <li><strong>Retention Objective (L<sub>retain</sub>):</strong> This term helps preserve the model's performance on unrelated tasks. It's formulated as:
        <img src="images/paper/retain.png" alt="Equation for Retention Objective" />
        <p>This objective encourages the model to maintain its original prediction probabilities when processing input tokens from the retain dataset, ensuring that unrelated knowledge remains intact.</p>
    </li>

    <li><strong>Conditional Fluency Objective (L<sub>fluency</sub>):</strong> This term ensures the model maintains text coherence when prompted with content related to erased concepts. It's defined as:
        <img src="images/paper/fluency.png" alt="Equation for Conditional Fluency Objective" />
        <p>This objective operates in two stages: First, it generates a sequence of synthesized training tokens by applying the erasing principle to the original model. Then, it trains the erased model to produce fluent and contextually different content in response to prompts about the erased concept.</p>
    </li>
</ol>

<p>By optimizing this combined loss, ELM achieves effective concept erasure while maintaining model fluency and general capabilities. </p>

<h2> Erasing an artistic style</h2>
  <p>Models like Stable Diffusion can mimic <a href="https://proximacentaurib.notion.site/About-Image-Synthesis-Style-Studies-4dcbd554f4b0403d802dc5b26fb3b8e9">the styles of more than 1500 artists</a>. Not all artists are excited about their art being mimicked by genrative models and wish to be opted-out of these models' vocubulary.
  Recent works have been working on <a href="https://spawning.ai">filtering the training data</a> to accomodate the opt-out requests from individuals. Eventhough such filtering would exclude the artists from future models that are trained on the filtered dataset, model editing may still be needed for certain artists that aren't fully addressed. We propose using UCE that is scalable, fast, and displays minimal interference with other artists. 
  To erase style, we use the name of the artist and steer them towards general prompts like "art" or "".</p>
  <figure class="center_image" style="margin-top: 30px">
    <center><img src="images/paper/style1.png" style="width:100%; max-width:800px"></center>
    <figcaption> Erasing 1 artist. On left, we show the original vs edited for the intended erasure. On the right, we show the interference with unerased artists. We find that our method efficiently erases while having the least inteference.
    </figcaption>
  </figure>

  <figure class="center_image" style="margin-top: 30px">
    <center><img src="images/paper/style2.png" style="width:100%; max-width:800px"></center>
    <figcaption> Erasing 5 artists at a time. On left, we show the original vs edited for the intended erasure. On the right, we show the interference with unerased artists. We find that our method efficiently erases while having the least inteference.
    </figcaption>
  </figure>

  <figure class="center_image" style="margin-top: 30px">
    <center><img src="images/paper/style3.png" style="width:100%; max-width:800px"></center>
    <figcaption> Erasing 10 artists at a time. On left, we show the original vs edited for the intended erasure. On the right, we show the interference with unerased artists. We find that our method efficiently erases while having the least inteference.
    </figcaption>
  </figure>

  <figure class="center_image" style="margin-top: 30px">
    <center><img src="images/paper/style4.png" style="width:100%; max-width:800px"></center>
    <figcaption> Erasing 50 artists at a time. On left, we show the original vs edited for the intended erasure. On the right, we show the interference with unerased artists. We find that our method efficiently erases while having the least inteference.
    </figcaption>
  </figure>
<h2> Debiasing a profession across gender and race</h2>
  <p> Previous debiasing methods address only dual attributed biases, however, attributes like race are multi-faceted. We propose a multi-faceted debiasing formulation that can be scaled for multiple concepts. Our method has strong debiasing results, improving the race and gender representation in diffusion models.
  <center><img src="images/paper/debias_equation.png" style="width:500px;padding-bottom:10px;"></center>
    <p>This formulation allows UCE to address multi-attribute biases like race. We show some quantitative results of our method displaying improved race and gender diversity.</p>
    <figure class="center_image" style="margin-top: 30px">
    <center><img src="images/paper/gender1.png" style="width:100%; max-width:800px"></center>
    <figcaption> Our method improves gender representation for professions in diffusion models.
    </figcaption>
  </figure>
  
  <figure class="center_image" style="margin-top: 30px">
    <center><img src="images/paper/gender2.png" style="width:100%; max-width:800px"></center>
    <figcaption> Our method improves gender representation for professions in diffusion models.
    </figcaption>
  </figure>
  
  <figure class="center_image" style="margin-top: 30px">
    <center><img src="images/paper/gender3.png" style="width:100%; max-width:800px"></center>
    <figcaption> Our method improves gender representation for professions in diffusion models.
    </figcaption>
  </figure>

   
 <figure class="center_image" style="margin-top: 30px">
    <center><img src="images/paper/race1.png" style="width:100%; max-width:800px"></center>
    <figcaption> Our method improves race representation for professions in diffusion models.
    </figcaption>
  </figure>

   
 <figure class="center_image" style="margin-top: 30px">
    <center><img src="images/paper/race2.png" style="width:100%; max-width:800px"></center>
    <figcaption> Our method improves race representation for professions in diffusion models.
    </figcaption>
  </figure>

<h2> Moderating an unsafe concept</h2>
  <p>We test our method on moderating unsafe concepts like <i>"nudity"</i>. We compare our method with <a href="https://erasing.baulab.info">ESD-u and ESD-x</a>. We find that our method has similar performance as ESD-x when erasing a single concept, but our method shows minimal interference with other concepts in the model. 
  We also see that moderating multiple unsafe concepts like <i>"harm, violence, child abuse, blood, nudity"</i>, our method shows a stronger moderation effect on the model as seen in the figure below.</p>
  <figure class="center_image" style="margin-top: 30px">
    <center><img src="images/paper/nudity_bar.png" style="width:100%; max-width:800px"></center>
    <figcaption> We show the percentage reduction in unsafe nudity samples compared to Original SD as classified by <a href="https://github.com/notAI-tech/NudeNet">Nudenet</a>. We find that our method has a superior performance when moderating multiple unsafe concepts.
    </figcaption>
  </figure>
  
<h2>How to cite</h2>

<p>The paper can be cited as follows.
</p>

<div class="card">
<h3 class="card-header">bibliography</h3>
<div class="card-block">
<p style="text-indent: -3em; margin-left: 3em;" class="card-text clickselect">
Rohit Gandikota, Hadas Orgad, Yonatan Belinkov, Joanna Materzy&#324;ska, David Bau. "<em>Unified Concept Editing in Diffusion Models.</em>"
IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2024.</nobr>
</p>
</div>
<h3 class="card-header">bibtex</h3>
<div class="card-block">
<pre class="card-text clickselect">
@article{gandikota2024unified,
  title={Unified Concept Editing in Diffusion Models},
  author={Rohit Gandikota and Hadas Orgad and Yonatan Belinkov and Joanna Materzy\'nska and David Bau},
  journal={IEEE/CVF Winter Conference on Applications of Computer Vision},
  year={2024}
}
</pre>
</div>
</div>
</p>

</div>
</div><!--row -->
</div> <!-- container -->

<footer class="nd-pagefooter">
  <div class="row">
    <div class="col-6 col-md text-center">
      <a href="https://baulab.info/">About the Bau Lab</a>
    </div>
  </div>
</footer>

</body>
<script>
$(document).on('click', '.clickselect', function(ev) {
  var range = document.createRange();
  range.selectNodeContents(this);
  var sel = window.getSelection();
  sel.removeAllRanges();
  sel.addRange(range);
});
</script>
</html>

